{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f58a8bc-9f2d-45c1-8e8f-f5582b16ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import image_dataset_from_directory\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a038be-78eb-4bef-9877-2f87b6e1d02c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65442070-e771-455e-b2a0-2389a8daf043",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path(r\"C:\\Users\\USER\\Documents\\Health_Tech_Initiative\\archive (32)\\cell_images_data\") \n",
    "train_dir = DATA_ROOT / \"train\"\n",
    "val_dir   = DATA_ROOT / \"val\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b92e0d-7a78-4327-8e31-b6d288625bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import params\n",
    "\n",
    "img_size = 180\n",
    "batch_size = 32\n",
    "seed = 42\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "initial_epochs = 8\n",
    "fine_tune_epochs = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b5fc75-6aa9-4a7a-b4f8-60eb0e8a2e6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54f24554-6d47-4915-a11b-47bb9a30a614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train folder: C:\\Users\\USER\\Documents\\Health_Tech_Initiative\\archive (32)\\cell_images_data\\train\n",
      "Val folder:   C:\\Users\\USER\\Documents\\Health_Tech_Initiative\\archive (32)\\cell_images_data\\val\n"
     ]
    }
   ],
   "source": [
    "# quick existence checks\n",
    "assert train_dir.exists(), f\"{train_dir} not found\"\n",
    "assert val_dir.exists(), f\"{val_dir} not found\"\n",
    "print(\"Train folder:\", train_dir)\n",
    "print(\"Val folder:  \", val_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3324d790-85ea-4f5e-9f82-0aaba346860c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "11b37a56-7782-47b0-95df-94b36cdb6998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22046 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#load datasets (labels inferred from subfolders; label_mode=int -> 0/1)\n",
    "\n",
    "train_ds = image_dataset_from_directory(\n",
    "    train_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    image_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    seed=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d1f7c22-c67c-4a85-a306-e60811db2f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5512 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_ds = image_dataset_from_directory(\n",
    "    val_dir,\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"int\",\n",
    "    image_size=(img_size, img_size),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "655723f2-6e88-4a0e-96d8-4d1f1e5b3367",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class names (index -> label): ['parasitized', 'uninfected']\n"
     ]
    }
   ],
   "source": [
    "print(\"Class names (index -> label):\", train_ds.class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5705ae98-5a82-4c1e-941b-46469f9125af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "091510fe-15d6-48f8-b7f3-c764ee589d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique: [0 1] counts (sampled): [3246 3154]\n",
      "unique: [0 1] counts (sampled): [2756 2756]\n"
     ]
    }
   ],
   "source": [
    "# 2) sanity counts (sampleed)\n",
    "def collect_counts(ds, max_batches=200):\n",
    "    labels=[]\n",
    "    for i, (_, y) in enumerate(ds):\n",
    "        labels.append(y.numpy().ravel())\n",
    "        if i+1 >= max_batches: break\n",
    "    labels = np.concatenate(labels)\n",
    "    print(\"unique:\", np.unique(labels), \"counts (sampled):\", np.bincount(labels.astype(int)))\n",
    "    return labels\n",
    "\n",
    "_ = collect_counts(train_ds, max_batches=200)\n",
    "_ = collect_counts(val_ds,   max_batches=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188ea11c-c0ad-4b5f-8b98-1447242686e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c1656b31-cd0c-4524-905d-d0b09484c1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) augmentation (training-only)\n",
    "\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.08),\n",
    "    layers.RandomZoom(0.08),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "22fa42ff-56eb-4fda-9438-156732775e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) preprocessing for EfficientNetB0\n",
    "# image_dataset_from_directory returns uint8 [0,255]. EfficientNet preprocess_input expects float in [0,255].\n",
    "preprocess_fn = tf.keras.applications.efficientnet.preprocess_input\n",
    "\n",
    "def prep_train(x, y):\n",
    "    x = tf.cast(x, tf.float32)  # make sure float32\n",
    "    x = preprocess_fn(x)        # EfficientNet preprocessing\n",
    "    x = data_augmentation(x)    # augmentation AFTER preprocess is OK (augmentation operates on floats)\n",
    "    return x, y\n",
    "\n",
    "def prep_val(x, y):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x = preprocess_fn(x)\n",
    "    return x, y\n",
    "\n",
    "train_ds = train_ds.map(prep_train, num_parallel_calls=AUTOTUNE).cache().prefetch(AUTOTUNE)\n",
    "val_ds   = val_ds.map(prep_val,   num_parallel_calls=AUTOTUNE).cache().prefetch(AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9dc9ff-26aa-402f-a1e2-06c495cadfe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2efd069f-a576-40f6-aa5d-eb764e9209ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │       <span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1280</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">163,968</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4 (\u001b[38;5;33mInputLayer\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m180\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ efficientnetb0 (\u001b[38;5;33mFunctional\u001b[0m)          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │       \u001b[38;5;34m4,049,571\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1280\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m163,968\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,213,668</span> (16.07 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,213,668\u001b[0m (16.07 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">164,097</span> (641.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m164,097\u001b[0m (641.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,049,571</span> (15.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,049,571\u001b[0m (15.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5) build model (EfficientNetB0 base + small head)\n",
    "base_model = EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(img_size,img_size,3), pooling=\"avg\")\n",
    "base_model.trainable = False\n",
    "\n",
    "inputs = keras.Input(shape=(img_size, img_size, 3))\n",
    "x = base_model(inputs, training=False)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "x = layers.Dense(128, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd42d8a9-4713-4928-b43c-962475496359",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "994a2940-5028-431c-a321-f4d32c5fc93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6) compile for head training\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\"), keras.metrics.Precision(name=\"precision\"), keras.metrics.Recall(name=\"recall\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "42628bda-d4a1-42ea-a256-013b73a0fd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) callbacks\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\"best_effnetb0.h5\", monitor=\"val_auc\", mode=\"max\", save_best_only=True),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=3, min_lr=1e-7),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_auc\", patience=6, restore_best_weights=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4416a5d0-420c-425c-9100-40aaacc032d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723ms/step - accuracy: 0.8012 - auc: 0.8795 - loss: 0.4254 - precision: 0.8051 - recall: 0.7758"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m632s\u001b[0m 891ms/step - accuracy: 0.8013 - auc: 0.8796 - loss: 0.4252 - precision: 0.8052 - recall: 0.7759 - val_accuracy: 0.9213 - val_auc: 0.9731 - val_loss: 0.2090 - val_precision: 0.9265 - val_recall: 0.9151 - learning_rate: 1.0000e-04\n",
      "Epoch 2/8\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658ms/step - accuracy: 0.9038 - auc: 0.9643 - loss: 0.2417 - precision: 0.8976 - recall: 0.9081"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m552s\u001b[0m 802ms/step - accuracy: 0.9038 - auc: 0.9643 - loss: 0.2417 - precision: 0.8976 - recall: 0.9081 - val_accuracy: 0.9318 - val_auc: 0.9770 - val_loss: 0.1880 - val_precision: 0.9334 - val_recall: 0.9300 - learning_rate: 1.0000e-04\n",
      "Epoch 3/8\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 615ms/step - accuracy: 0.9128 - auc: 0.9688 - loss: 0.2244 - precision: 0.9053 - recall: 0.9188"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m523s\u001b[0m 759ms/step - accuracy: 0.9128 - auc: 0.9688 - loss: 0.2244 - precision: 0.9053 - recall: 0.9188 - val_accuracy: 0.9351 - val_auc: 0.9780 - val_loss: 0.1840 - val_precision: 0.9366 - val_recall: 0.9332 - learning_rate: 1.0000e-04\n",
      "Epoch 4/8\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9200 - auc: 0.9729 - loss: 0.2087 - precision: 0.9131 - recall: 0.9257"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 744ms/step - accuracy: 0.9200 - auc: 0.9729 - loss: 0.2087 - precision: 0.9131 - recall: 0.9257 - val_accuracy: 0.9363 - val_auc: 0.9794 - val_loss: 0.1783 - val_precision: 0.9381 - val_recall: 0.9343 - learning_rate: 1.0000e-04\n",
      "Epoch 5/8\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 603ms/step - accuracy: 0.9245 - auc: 0.9748 - loss: 0.2004 - precision: 0.9230 - recall: 0.9238"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m516s\u001b[0m 748ms/step - accuracy: 0.9245 - auc: 0.9748 - loss: 0.2004 - precision: 0.9230 - recall: 0.9238 - val_accuracy: 0.9381 - val_auc: 0.9803 - val_loss: 0.1735 - val_precision: 0.9377 - val_recall: 0.9387 - learning_rate: 1.0000e-04\n",
      "Epoch 6/8\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 592ms/step - accuracy: 0.9222 - auc: 0.9753 - loss: 0.1994 - precision: 0.9172 - recall: 0.9258"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m509s\u001b[0m 739ms/step - accuracy: 0.9222 - auc: 0.9753 - loss: 0.1994 - precision: 0.9172 - recall: 0.9258 - val_accuracy: 0.9396 - val_auc: 0.9807 - val_loss: 0.1716 - val_precision: 0.9369 - val_recall: 0.9427 - learning_rate: 1.0000e-04\n",
      "Epoch 7/8\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 594ms/step - accuracy: 0.9265 - auc: 0.9755 - loss: 0.1965 - precision: 0.9204 - recall: 0.9310"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m510s\u001b[0m 741ms/step - accuracy: 0.9265 - auc: 0.9755 - loss: 0.1965 - precision: 0.9204 - recall: 0.9310 - val_accuracy: 0.9385 - val_auc: 0.9810 - val_loss: 0.1703 - val_precision: 0.9371 - val_recall: 0.9401 - learning_rate: 1.0000e-04\n",
      "Epoch 8/8\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 599ms/step - accuracy: 0.9278 - auc: 0.9780 - loss: 0.1877 - precision: 0.9228 - recall: 0.9316"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m513s\u001b[0m 744ms/step - accuracy: 0.9278 - auc: 0.9780 - loss: 0.1877 - precision: 0.9228 - recall: 0.9316 - val_accuracy: 0.9376 - val_auc: 0.9813 - val_loss: 0.1730 - val_precision: 0.9414 - val_recall: 0.9332 - learning_rate: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# 8) train head\n",
    "history1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=initial_epochs,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a311caca-68b0-4364-89e4-094369adf08b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff7aeaf8-b09f-4861-8807-d1340c70bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) fine-tune: unfreeze top layers of base\n",
    "base_model.trainable = True\n",
    "# Freeze lower layers, unfreeze the top N layers for fine-tuning\n",
    "fine_tune_at = len(base_model.layers) - 50  # adjust if needed\n",
    "for layer in base_model.layers[:fine_tune_at]:\n",
    "    layer.trainable = False\n",
    "for layer in base_model.layers[fine_tune_at:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe7f2cf-d270-49c4-8d0b-4d312c00edea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "01d09bc3-01ee-4e28-8567-c3a5b46d5fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\", keras.metrics.AUC(name=\"auc\"), keras.metrics.Precision(name=\"precision\"), keras.metrics.Recall(name=\"recall\")]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "537621cb-65c5-4cf2-a53e-9d4196f10929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9641 - loss: 0.2442 - precision: 0.9046 - recall: 0.8996"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m850s\u001b[0m 1s/step - accuracy: 0.9042 - auc: 0.9641 - loss: 0.2442 - precision: 0.9046 - recall: 0.8996 - val_accuracy: 0.9445 - val_auc: 0.9837 - val_loss: 0.1623 - val_precision: 0.9271 - val_recall: 0.9648 - learning_rate: 1.0000e-05\n",
      "Epoch 2/12\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757ms/step - accuracy: 0.9360 - auc: 0.9812 - loss: 0.1728 - precision: 0.9238 - recall: 0.9483"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m599s\u001b[0m 870ms/step - accuracy: 0.9360 - auc: 0.9812 - loss: 0.1728 - precision: 0.9238 - recall: 0.9483 - val_accuracy: 0.9487 - val_auc: 0.9861 - val_loss: 0.1505 - val_precision: 0.9340 - val_recall: 0.9655 - learning_rate: 1.0000e-05\n",
      "Epoch 3/12\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909ms/step - accuracy: 0.9454 - auc: 0.9869 - loss: 0.1427 - precision: 0.9325 - recall: 0.9584"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m742s\u001b[0m 1s/step - accuracy: 0.9454 - auc: 0.9869 - loss: 0.1427 - precision: 0.9325 - recall: 0.9584 - val_accuracy: 0.9514 - val_auc: 0.9887 - val_loss: 0.1377 - val_precision: 0.9390 - val_recall: 0.9655 - learning_rate: 1.0000e-05\n",
      "Epoch 5/12\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904ms/step - accuracy: 0.9495 - auc: 0.9887 - loss: 0.1316 - precision: 0.9377 - recall: 0.9612"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m753s\u001b[0m 1s/step - accuracy: 0.9495 - auc: 0.9887 - loss: 0.1316 - precision: 0.9377 - recall: 0.9612 - val_accuracy: 0.9528 - val_auc: 0.9893 - val_loss: 0.1333 - val_precision: 0.9401 - val_recall: 0.9673 - learning_rate: 1.0000e-05\n",
      "Epoch 6/12\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 924ms/step - accuracy: 0.9647 - auc: 0.9935 - loss: 0.0970 - precision: 0.9555 - recall: 0.9737 - val_accuracy: 0.9561 - val_auc: 0.9897 - val_loss: 0.1262 - val_precision: 0.9454 - val_recall: 0.9681 - learning_rate: 1.0000e-05\n",
      "Epoch 11/12\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797ms/step - accuracy: 0.9658 - auc: 0.9942 - loss: 0.0931 - precision: 0.9556 - recall: 0.9759"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m636s\u001b[0m 923ms/step - accuracy: 0.9658 - auc: 0.9942 - loss: 0.0931 - precision: 0.9556 - recall: 0.9759 - val_accuracy: 0.9574 - val_auc: 0.9903 - val_loss: 0.1231 - val_precision: 0.9465 - val_recall: 0.9695 - learning_rate: 1.0000e-05\n",
      "Epoch 12/12\n",
      "\u001b[1m689/689\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m610s\u001b[0m 886ms/step - accuracy: 0.9657 - auc: 0.9950 - loss: 0.0871 - precision: 0.9576 - recall: 0.9735 - val_accuracy: 0.9574 - val_auc: 0.9902 - val_loss: 0.1244 - val_precision: 0.9478 - val_recall: 0.9681 - learning_rate: 1.0000e-05\n"
     ]
    }
   ],
   "source": [
    "history2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=fine_tune_epochs,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8c1dd27-5a58-41fb-963d-772beda207fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8590e564-f18b-454a-8957-8a21afc81f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 517ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 551ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 541ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 525ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 566ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 514ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 606ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 477ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 480ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 478ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 475ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 483ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 474ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 481ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 487ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 486ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 485ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 473ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 527ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 516ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 528ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 522ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 482ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 498ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 497ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 500ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 569ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 537ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 577ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 533ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 484ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 479ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 515ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 488ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 476ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 501ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 504ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 508ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 534ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 529ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 553ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 556ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 540ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 506ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 503ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 538ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 513ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 545ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 510ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 509ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 500ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 499ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 526ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 512ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 511ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 524ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 502ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 559ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 505ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 523ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 775ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3s/step\n",
      "Confusion matrix:\n",
      " [[2605  151]\n",
      " [  84 2672]]\n",
      "\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9688    0.9452    0.9568      2756\n",
      "           1     0.9465    0.9695    0.9579      2756\n",
      "\n",
      "    accuracy                         0.9574      5512\n",
      "   macro avg     0.9576    0.9574    0.9574      5512\n",
      "weighted avg     0.9576    0.9574    0.9574      5512\n",
      "\n",
      "ROC AUC: 0.9916174447728245\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 10) Final evaluation & diagnostics\n",
    "y_true = []\n",
    "y_probs = []\n",
    "for x_batch, y_batch in val_ds:\n",
    "    y_true.append(y_batch.numpy().ravel())\n",
    "    y_probs.append(model.predict(x_batch).ravel())\n",
    "y_true = np.concatenate(y_true)\n",
    "y_probs = np.concatenate(y_probs)\n",
    "y_pred = (y_probs > 0.5).astype(int)\n",
    "\n",
    "print(\"Confusion matrix:\\n\", confusion_matrix(y_true, y_pred))\n",
    "print(\"\\nClassification report:\\n\", classification_report(y_true, y_pred, digits=4))\n",
    "print(\"ROC AUC:\", roc_auc_score(y_true, y_probs))\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "plt.hist(y_probs, bins=40)\n",
    "plt.title(\"Validation predicted probabilities\")\n",
    "plt.xlabel(\"probability\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abe35fe-1f0b-4b12-a501-516cd8abe1ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8bb66928-68db-45b5-ac4a-bf30f997727a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 147ms/step\n",
      "Prediction Probability.: 0.57917994\n",
      "Predicted Class.: Parasitized\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "img_path = r\"C:\\Users\\USER\\Documents\\Health_Tech_Initiative\\archive (32)\\cell_images_data\\train\\parasitized\\C39P4thinF_original_IMG_20150622_105102_cell_96.png\"\n",
    "\n",
    "# Load & preprocess Image\n",
    "img = image.load_img(img_path, target_size =(180,180))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis =0)/255.0\n",
    "\n",
    "# Predict\n",
    "pred = model.predict(img_array)\n",
    "\n",
    "# For binary classification\n",
    "prob = pred[0][0]\n",
    "label = \"Parasitized\" if prob>0.5 else \"Uninfected\"\n",
    "\n",
    "print(\"Prediction Probability.:\", prob)\n",
    "print(\"Predicted Class.:\", label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798ab3d-738b-4e15-8633-07958010f6c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "627ca877-2bbc-4c4a-880e-06f8a6a80c04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class_names (index -> label): [(0, 'parasitized'), (1, 'uninfected')]\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "train_dir = Path(r'C:\\Users\\USER\\Documents\\Health_Tech_Initiative\\archive (32)\\cell_images_data\\train')   # <-- update to your actual train folder\n",
    "class_names = sorted([p.name for p in train_dir.iterdir() if p.is_dir()])\n",
    "print(\"class_names (index -> label):\", list(enumerate(class_names)))\n",
    "# Example output: [(0,'parasitized'), (1,'uninfected')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9317e7b4-769f-45f4-ba80-dbacf7724dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final model to final_effnetb0_model.h5\n"
     ]
    }
   ],
   "source": [
    "# 11) Save final model (best one already saved by ModelCheckpoint)\n",
    "model.save(\"finalfinal_effnetb0_model.h5\")\n",
    "print(\"Saved final model to final_effnetb0_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee956ff-0c9a-456f-bb66-1f47e77a5d23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
